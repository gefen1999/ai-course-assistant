{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:11.984388Z",
     "start_time": "2025-10-03T10:27:10.348691Z"
    }
   },
   "source": "pip install pinecone",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (7.3.0)\r\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone) (2025.8.3)\r\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone) (1.7.0)\r\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone) (0.0.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone) (2.9.0.post0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone) (4.14.1)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone) (2.5.0)\r\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.virtualenvs/final-project/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.1.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/home/student/.virtualenvs/final-project/bin/python3 -m pip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:23.132208Z",
     "start_time": "2025-10-03T10:27:12.581646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "import docx\n",
    "from pdfminer.high_level import extract_text\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SpacyTextSplitter\n",
    ")\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import spacy\n",
    "import subprocess\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n"
   ],
   "id": "954f6556c73c42ef",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.virtualenvs/final-project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/student/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:23.311796Z",
     "start_time": "2025-10-03T10:27:23.308406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensure_spacy_model(model_name=\"en_core_web_sm\"):\n",
    "    \"\"\"Ensure that the given spaCy model is installed.\"\"\"\n",
    "    try:\n",
    "        spacy.load(model_name)\n",
    "    except OSError:\n",
    "        print(f\"âš ï¸ spaCy model '{model_name}' not found. Downloading...\")\n",
    "        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model_name], check=True)\n",
    "        print(f\"âœ… Downloaded spaCy model: {model_name}\")"
   ],
   "id": "2950dc3c0819cbd5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:23.476929Z",
     "start_time": "2025-10-03T10:27:23.473483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recursive_chunking(texts: list[str], chunk_size: int, overlap: int) -> list[str]:\n",
    "    char_size = chunk_size * AVG_WORD_LEN\n",
    "    char_overlap = overlap * AVG_WORD_LEN\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    chunks = []\n",
    "    for text in texts:\n",
    "        chunks.extend(splitter.split_text(text))\n",
    "    return chunks"
   ],
   "id": "314469599e0ff1e6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:23.678200Z",
     "start_time": "2025-10-03T10:27:23.674619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def overlapping_chunking(texts: list[str], chunk_size: int, overlap: int) -> list[str]:\n",
    "    chunks = []\n",
    "    step = chunk_size - overlap\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        for i in range(0, len(words), step):\n",
    "            chunk = \" \".join(words[i:i + chunk_size])\n",
    "            if chunk:\n",
    "                chunks.append(chunk.strip())\n",
    "    return chunks"
   ],
   "id": "835968f47beb301e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:23.877306Z",
     "start_time": "2025-10-03T10:27:23.873856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def spacy_chunking(texts: list[str], chunk_size: int, overlap: int) -> list[str]:\n",
    "    char_size = chunk_size * AVG_WORD_LEN\n",
    "    char_overlap = overlap * AVG_WORD_LEN\n",
    "    splitter = SpacyTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    chunks = []\n",
    "    for text in texts:\n",
    "        chunks.extend(splitter.split_text(text))\n",
    "    return chunks"
   ],
   "id": "81e0aaf687a79b7d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:24.077967Z",
     "start_time": "2025-10-03T10:27:24.074900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def select_chunking_strategy(strategy_name: str):\n",
    "    strategies = {\n",
    "        \"recursive\": recursive_chunking,\n",
    "        \"overlapping\": overlapping_chunking,\n",
    "        \"spacy\": spacy_chunking,\n",
    "    }\n",
    "    return strategies.get(strategy_name)"
   ],
   "id": "e35ae3500f0c0634",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:24.280984Z",
     "start_time": "2025-10-03T10:27:24.274341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_zip_file(zip_path: Path, extract_to: Path):\n",
    "    if not extract_to.exists():\n",
    "        extract_to.mkdir(parents=True, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Extracted {zip_path} to {extract_to}\")\n",
    "\n",
    "def remove_cid_artifacts(text):\n",
    "    return re.sub(r'\\(cid:\\d+\\)', '', text)\n",
    "\n",
    "def read_pdf(path: Path) -> str:\n",
    "    try:\n",
    "        text = extract_text(str(path))\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error reading {path.name}: {e}\")\n",
    "        text = \"\"\n",
    "    return remove_cid_artifacts(text)\n",
    "\n",
    "def read_docx(path: Path) -> str:\n",
    "    doc = docx.Document(str(path))\n",
    "    return \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\.\\,\\;\\:\\?\\!\\-\\s]\", \" \", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "def embed_chunks(texts: list[str], model: SentenceTransformer) -> np.ndarray:\n",
    "    if not texts:\n",
    "        return np.empty((0, model.get_sentence_embedding_dimension()), dtype=\"float32\")\n",
    "    embs = model.encode(texts, convert_to_numpy=True)\n",
    "    return normalize(embs, axis=1).astype(\"float32\")"
   ],
   "id": "9cfe297b4167371f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:24.475863Z",
     "start_time": "2025-10-03T10:27:24.469939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_index(pc, index_name, dimension, metric):\n",
    "    existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "    if index_name not in existing_indexes:\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            metric = metric,\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "        )\n",
    "        print(f\"Created new Pinecone index: {index_name}\")\n",
    "    else:\n",
    "        print(f\"Using existing Pinecone index: {index_name}\")\n",
    "\n",
    "def save_to_pinecone(records, embeddings, pc, index_name, namespace=\"default\"):\n",
    "    index = pc.Index(index_name)\n",
    "    vectors = []\n",
    "    for i, record in enumerate(records):\n",
    "        vectors.append({\n",
    "            \"id\": f\"{Path(record['file']).stem}_chunk_{record['chunk_id']}\",\n",
    "            \"values\": embeddings[i].tolist(),\n",
    "            \"metadata\": {\n",
    "                \"file\": Path(record['file']).name,\n",
    "                \"chunk_id\": record['chunk_id'],\n",
    "                \"text\": record['text'],\n",
    "                \"length\": record['length'],\n",
    "            }\n",
    "        })\n",
    "    for i in range(0, len(vectors), 100):\n",
    "        index.upsert(vectors=vectors[i:i+100], namespace=namespace)\n",
    "    print(f\"ðŸ“Œ Saved {len(vectors)} vectors to Pinecone namespace '{namespace}'.\")"
   ],
   "id": "57d2d1715b554fa3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:24.636983Z",
     "start_time": "2025-10-03T10:27:24.632338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"multi-qa-mpnet-base-dot-v1\"\n",
    "ZIP_PATH = Path(\"Eng_data.zip\")\n",
    "DATA_DIR = ZIP_PATH.with_suffix(\"\")\n",
    "WORDS_PER_CHUNK = 500\n",
    "WORDS_OVERLAP = 100\n",
    "AVG_WORD_LEN = 6  # adjust if needed\n",
    "OVERLAP = 200\n",
    "PINECONE_INDEX_NAME = 'dotproduct'\n",
    "CHUNK_STRATEGY = \"spacy\"  # Options: recursive / overlapping / spacy\n",
    "NAMESPACE = f\"ENG-{CHUNK_STRATEGY}\"\n",
    "\n",
    "with open(r\"../src/api_keys.json\") as f:\n",
    "    api_keys = json.load(f)\n",
    "pc = Pinecone(api_key=api_keys[\"pinecone_anna\"])"
   ],
   "id": "372fc45829c883ee",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:31.092661Z",
     "start_time": "2025-10-03T10:27:25.177043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading model\n",
    "print(f\"[1/4] Loading model '{MODEL_NAME}'...\")\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "dimension = model.get_sentence_embedding_dimension()\n",
    "create_index(pc, PINECONE_INDEX_NAME, dimension, PINECONE_INDEX_NAME)"
   ],
   "id": "e642ef6bd7088d1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4] Loading model 'multi-qa-mpnet-base-dot-v1'...\n",
      "Created new Pinecone index: dotproduct\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:53.154414Z",
     "start_time": "2025-10-03T10:27:32.885767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[2/4] Extracting zip and reading documents...\")\n",
    "extract_zip_file(ZIP_PATH, DATA_DIR)\n",
    "raw_texts = []\n",
    "sources = []\n",
    "all_files = list(DATA_DIR.rglob(\"*\"))\n",
    "with tqdm(all_files, desc=\"Reading files\") as pbar:\n",
    "    for path in pbar:\n",
    "        if path.suffix.lower() == \".pdf\":\n",
    "            text = read_pdf(path)\n",
    "        elif path.suffix.lower() == \".docx\":\n",
    "            text = read_docx(path)\n",
    "        else:\n",
    "            continue\n",
    "        cleaned = clean_text(text)\n",
    "        raw_texts.append(cleaned)\n",
    "        sources.append(str(path))"
   ],
   "id": "1a4d3ab975948f93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Eng_data.zip to Eng_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/4] Extracting zip and reading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
      "Reading files:  14%|â–ˆâ–        | 1/7 [00:13<01:22, 13.80s/it]Cannot set gray non-stroke color because /'P117' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P125' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P133' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P141' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P151' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P161' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P171' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P179' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P189' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P199' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P207' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P217' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P227' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P235' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P243' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P253' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P263' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P271' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P281' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P291' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P299' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P307' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P315' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P24' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P32' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P40' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P48' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P58' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P68' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P78' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P86' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P96' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P106' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P114' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P124' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P134' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P142' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P150' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P160' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P170' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P178' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P188' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P198' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P206' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P214' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P222' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P22' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P38' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P46' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P56' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P66' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P76' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P84' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P94' is an invalid float value\n",
      "Reading files:  14%|â–ˆâ–        | 1/7 [00:18<01:52, 18.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m pbar:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m path\u001B[38;5;241m.\u001B[39msuffix\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pdf\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m----> 9\u001B[0m         text \u001B[38;5;241m=\u001B[39m \u001B[43mread_pdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m path\u001B[38;5;241m.\u001B[39msuffix\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.docx\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     11\u001B[0m         text \u001B[38;5;241m=\u001B[39m read_docx(path)\n",
      "Cell \u001B[0;32mIn[8], line 13\u001B[0m, in \u001B[0;36mread_pdf\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mread_pdf\u001B[39m(path: Path) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 13\u001B[0m         text \u001B[38;5;241m=\u001B[39m \u001B[43mextract_text\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     15\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mâš ï¸ Error reading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/high_level.py:184\u001B[0m, in \u001B[0;36mextract_text\u001B[0;34m(pdf_file, password, page_numbers, maxpages, caching, codec, laparams)\u001B[0m\n\u001B[1;32m    175\u001B[0m interpreter \u001B[38;5;241m=\u001B[39m PDFPageInterpreter(rsrcmgr, device)\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m page \u001B[38;5;129;01min\u001B[39;00m PDFPage\u001B[38;5;241m.\u001B[39mget_pages(\n\u001B[1;32m    178\u001B[0m     fp,\n\u001B[1;32m    179\u001B[0m     page_numbers,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    182\u001B[0m     caching\u001B[38;5;241m=\u001B[39mcaching,\n\u001B[1;32m    183\u001B[0m ):\n\u001B[0;32m--> 184\u001B[0m     \u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_page\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output_string\u001B[38;5;241m.\u001B[39mgetvalue()\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdfinterp.py:1210\u001B[0m, in \u001B[0;36mPDFPageInterpreter.process_page\u001B[0;34m(self, page)\u001B[0m\n\u001B[1;32m   1208\u001B[0m     ctm \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39mx0, \u001B[38;5;241m-\u001B[39my0)\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mbegin_page(page, ctm)\n\u001B[0;32m-> 1210\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender_contents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresources\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1211\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mend_page(page)\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdfinterp.py:1231\u001B[0m, in \u001B[0;36mPDFPageInterpreter.render_contents\u001B[0;34m(self, resources, streams, ctm)\u001B[0m\n\u001B[1;32m   1229\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_resources(resources)\n\u001B[1;32m   1230\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_state(ctm)\n\u001B[0;32m-> 1231\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstreams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdfinterp.py:1257\u001B[0m, in \u001B[0;36mPDFPageInterpreter.execute\u001B[0;34m(self, streams)\u001B[0m\n\u001B[1;32m   1255\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexec: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, name, args)\n\u001B[1;32m   1256\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m==\u001B[39m nargs:\n\u001B[0;32m-> 1257\u001B[0m         \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1259\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexec: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, name)\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdfinterp.py:1164\u001B[0m, in \u001B[0;36mPDFPageInterpreter.do_Do\u001B[0;34m(self, xobjid_arg)\u001B[0m\n\u001B[1;32m   1162\u001B[0m xobjid \u001B[38;5;241m=\u001B[39m literal_name(xobjid_arg)\n\u001B[1;32m   1163\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1164\u001B[0m     xobj \u001B[38;5;241m=\u001B[39m \u001B[43mstream_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxobjmap\u001B[49m\u001B[43m[\u001B[49m\u001B[43mxobjid\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m   1166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m settings\u001B[38;5;241m.\u001B[39mSTRICT:\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdftypes.py:216\u001B[0m, in \u001B[0;36mstream_value\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mstream_value\u001B[39m(x: \u001B[38;5;28mobject\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPDFStream\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 216\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mresolve1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, PDFStream):\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m settings\u001B[38;5;241m.\u001B[39mSTRICT:\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdftypes.py:117\u001B[0m, in \u001B[0;36mresolve1\u001B[0;34m(x, default)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Resolves an object.\u001B[39;00m\n\u001B[1;32m    112\u001B[0m \n\u001B[1;32m    113\u001B[0m \u001B[38;5;124;03mIf this is an array or dictionary, it may still contains\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;124;03msome indirect objects inside.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, PDFObjRef):\n\u001B[0;32m--> 117\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdefault\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdftypes.py:105\u001B[0m, in \u001B[0;36mPDFObjRef.resolve\u001B[0;34m(self, default)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdoc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdoc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetobj\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobjid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m PDFObjectNotFound:\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdfdocument.py:864\u001B[0m, in \u001B[0;36mPDFDocument.getobj\u001B[0;34m(self, objid)\u001B[0m\n\u001B[1;32m    862\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getobj_objstm(stream, index, objid)\n\u001B[1;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 864\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getobj_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecipher:\n\u001B[1;32m    866\u001B[0m         obj \u001B[38;5;241m=\u001B[39m decipher_all(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecipher, objid, genno, obj)\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/pdfdocument.py:819\u001B[0m, in \u001B[0;36mPDFDocument._getobj_parse\u001B[0;34m(self, pos, objid)\u001B[0m\n\u001B[1;32m    817\u001B[0m (_, objid1) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parser\u001B[38;5;241m.\u001B[39mnexttoken()  \u001B[38;5;66;03m# objid\u001B[39;00m\n\u001B[1;32m    818\u001B[0m (_, genno) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parser\u001B[38;5;241m.\u001B[39mnexttoken()  \u001B[38;5;66;03m# genno\u001B[39;00m\n\u001B[0;32m--> 819\u001B[0m (_, kwd) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnexttoken\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m \u001B[38;5;66;03m# hack around malformed pdf files\u001B[39;00m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;66;03m# copied from https://github.com/jaepil/pdfminer3k/blob/master/\u001B[39;00m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;66;03m# pdfminer/pdfparser.py#L399\u001B[39;00m\n\u001B[1;32m    823\u001B[0m \u001B[38;5;66;03m# to solve https://github.com/pdfminer/pdfminer.six/issues/56\u001B[39;00m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;66;03m# assert objid1 == objid, str((objid1, objid))\u001B[39;00m\n\u001B[1;32m    825\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m objid1 \u001B[38;5;241m!=\u001B[39m objid:\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/psparser.py:510\u001B[0m, in \u001B[0;36mPSBaseParser.nexttoken\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfillbuf()\n\u001B[0;32m--> 510\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcharpos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse1\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcharpos\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m PSEOF:\n\u001B[1;32m    512\u001B[0m     \u001B[38;5;66;03m# If we hit EOF in the middle of a token, try to parse\u001B[39;00m\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;66;03m# it by tacking on whitespace, and delay raising PSEOF\u001B[39;00m\n\u001B[1;32m    514\u001B[0m     \u001B[38;5;66;03m# until next time around\u001B[39;00m\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcharpos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse1(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/final-project/lib/python3.10/site-packages/pdfminer/psparser.py:398\u001B[0m, in \u001B[0;36mPSBaseParser._parse_keyword\u001B[0;34m(self, s, i)\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_parse_keyword\u001B[39m(\u001B[38;5;28mself\u001B[39m, s: \u001B[38;5;28mbytes\u001B[39m, i: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[0;32m--> 398\u001B[0m     m \u001B[38;5;241m=\u001B[39m \u001B[43mEND_KEYWORD\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m m:\n\u001B[1;32m    400\u001B[0m         j \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39mstart(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:53.323159Z",
     "start_time": "2025-09-23T17:22:04.203117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[3/4] Chunking text...\")\n",
    "if CHUNK_STRATEGY == \"spacy\":\n",
    "  ensure_spacy_model(\"en_core_web_sm\")\n",
    "\n",
    "chunk_func = select_chunking_strategy(CHUNK_STRATEGY)\n",
    "#chunks = chunk_func(raw_texts, chunk_size=CHUNK_SIZE, overlap=OVERLAP)\n",
    "\n",
    "records = []\n",
    "for file_path, text in zip(sources, raw_texts):\n",
    "    file_chunks = chunk_func([text], chunk_size=WORDS_PER_CHUNK, overlap=WORDS_OVERLAP)\n",
    "    file_name = Path(file_path).stem\n",
    "    for i, chunk in enumerate(file_chunks):\n",
    "        records.append({\n",
    "            \"file\": file_name,\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk,\n",
    "            \"length\": len(chunk.split()),\n",
    "        })\n",
    "\n",
    "print(f\"â†’ Created {len(records)} chunks\")"
   ],
   "id": "8773b7ea3df0386d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/5] Chunking text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.virtualenvs/final-project/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Created a chunk of size 1163, which is longer than the specified 1000\n",
      "Created a chunk of size 1163, which is longer than the specified 1000\n",
      "Created a chunk of size 1170, which is longer than the specified 1000\n",
      "Created a chunk of size 1170, which is longer than the specified 1000\n",
      "Created a chunk of size 2562, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1212, which is longer than the specified 1000\n",
      "Created a chunk of size 2017, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1196, which is longer than the specified 1000\n",
      "Created a chunk of size 2190, which is longer than the specified 1000\n",
      "Created a chunk of size 1161, which is longer than the specified 1000\n",
      "Created a chunk of size 1136, which is longer than the specified 1000\n",
      "Created a chunk of size 1055, which is longer than the specified 1000\n",
      "Created a chunk of size 1609, which is longer than the specified 1000\n",
      "Created a chunk of size 1276, which is longer than the specified 1000\n",
      "Created a chunk of size 2154, which is longer than the specified 1000\n",
      "Created a chunk of size 1192, which is longer than the specified 1000\n",
      "Created a chunk of size 1167, which is longer than the specified 1000\n",
      "Created a chunk of size 1008, which is longer than the specified 1000\n",
      "Created a chunk of size 1092, which is longer than the specified 1000\n",
      "Created a chunk of size 1059, which is longer than the specified 1000\n",
      "Created a chunk of size 1257, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n",
      "Created a chunk of size 2321, which is longer than the specified 1000\n",
      "Created a chunk of size 1085, which is longer than the specified 1000\n",
      "Created a chunk of size 2039, which is longer than the specified 1000\n",
      "Created a chunk of size 1149, which is longer than the specified 1000\n",
      "Created a chunk of size 1412, which is longer than the specified 1000\n",
      "Created a chunk of size 1087, which is longer than the specified 1000\n",
      "Created a chunk of size 1513, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1798, which is longer than the specified 1000\n",
      "Created a chunk of size 1253, which is longer than the specified 1000\n",
      "Created a chunk of size 1186, which is longer than the specified 1000\n",
      "Created a chunk of size 3053, which is longer than the specified 1000\n",
      "Created a chunk of size 1528, which is longer than the specified 1000\n",
      "Created a chunk of size 1533, which is longer than the specified 1000\n",
      "Created a chunk of size 1828, which is longer than the specified 1000\n",
      "Created a chunk of size 2754, which is longer than the specified 1000\n",
      "Created a chunk of size 4462, which is longer than the specified 1000\n",
      "Created a chunk of size 4381, which is longer than the specified 1000\n",
      "Created a chunk of size 1620, which is longer than the specified 1000\n",
      "Created a chunk of size 2804, which is longer than the specified 1000\n",
      "Created a chunk of size 2754, which is longer than the specified 1000\n",
      "Created a chunk of size 4462, which is longer than the specified 1000\n",
      "Created a chunk of size 4381, which is longer than the specified 1000\n",
      "Created a chunk of size 1620, which is longer than the specified 1000\n",
      "Created a chunk of size 2804, which is longer than the specified 1000\n",
      "Created a chunk of size 2844, which is longer than the specified 1000\n",
      "Created a chunk of size 1803, which is longer than the specified 1000\n",
      "Created a chunk of size 1493, which is longer than the specified 1000\n",
      "Created a chunk of size 2807, which is longer than the specified 1000\n",
      "Created a chunk of size 1305, which is longer than the specified 1000\n",
      "Created a chunk of size 1370, which is longer than the specified 1000\n",
      "Created a chunk of size 1138, which is longer than the specified 1000\n",
      "Created a chunk of size 1498, which is longer than the specified 1000\n",
      "Created a chunk of size 1225, which is longer than the specified 1000\n",
      "Created a chunk of size 1259, which is longer than the specified 1000\n",
      "Created a chunk of size 1060, which is longer than the specified 1000\n",
      "Created a chunk of size 1383, which is longer than the specified 1000\n",
      "Created a chunk of size 1799, which is longer than the specified 1000\n",
      "Created a chunk of size 1140, which is longer than the specified 1000\n",
      "Created a chunk of size 1374, which is longer than the specified 1000\n",
      "Created a chunk of size 1096, which is longer than the specified 1000\n",
      "Created a chunk of size 1133, which is longer than the specified 1000\n",
      "Created a chunk of size 1138, which is longer than the specified 1000\n",
      "Created a chunk of size 2152, which is longer than the specified 1000\n",
      "Created a chunk of size 1606, which is longer than the specified 1000\n",
      "Created a chunk of size 1360, which is longer than the specified 1000\n",
      "Created a chunk of size 1283, which is longer than the specified 1000\n",
      "Created a chunk of size 3534, which is longer than the specified 1000\n",
      "Created a chunk of size 1405, which is longer than the specified 1000\n",
      "Created a chunk of size 1037, which is longer than the specified 1000\n",
      "Created a chunk of size 1551, which is longer than the specified 1000\n",
      "Created a chunk of size 1064, which is longer than the specified 1000\n",
      "Created a chunk of size 1900, which is longer than the specified 1000\n",
      "Created a chunk of size 1027, which is longer than the specified 1000\n",
      "Created a chunk of size 1672, which is longer than the specified 1000\n",
      "Created a chunk of size 2007, which is longer than the specified 1000\n",
      "Created a chunk of size 1632, which is longer than the specified 1000\n",
      "Created a chunk of size 1275, which is longer than the specified 1000\n",
      "Created a chunk of size 2070, which is longer than the specified 1000\n",
      "Created a chunk of size 1066, which is longer than the specified 1000\n",
      "Created a chunk of size 1705, which is longer than the specified 1000\n",
      "Created a chunk of size 4516, which is longer than the specified 1000\n",
      "Created a chunk of size 1252, which is longer than the specified 1000\n",
      "Created a chunk of size 1017, which is longer than the specified 1000\n",
      "Created a chunk of size 1254, which is longer than the specified 1000\n",
      "Created a chunk of size 1028, which is longer than the specified 1000\n",
      "Created a chunk of size 2007, which is longer than the specified 1000\n",
      "Created a chunk of size 1423, which is longer than the specified 1000\n",
      "Created a chunk of size 1664, which is longer than the specified 1000\n",
      "Created a chunk of size 1191, which is longer than the specified 1000\n",
      "Created a chunk of size 2193, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n",
      "Created a chunk of size 1382, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1325, which is longer than the specified 1000\n",
      "Created a chunk of size 2885, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n",
      "Created a chunk of size 1615, which is longer than the specified 1000\n",
      "Created a chunk of size 1266, which is longer than the specified 1000\n",
      "Created a chunk of size 1332, which is longer than the specified 1000\n",
      "Created a chunk of size 1027, which is longer than the specified 1000\n",
      "Created a chunk of size 1161, which is longer than the specified 1000\n",
      "Created a chunk of size 1134, which is longer than the specified 1000\n",
      "Created a chunk of size 1413, which is longer than the specified 1000\n",
      "Created a chunk of size 2332, which is longer than the specified 1000\n",
      "Created a chunk of size 1143, which is longer than the specified 1000\n",
      "Created a chunk of size 1498, which is longer than the specified 1000\n",
      "Created a chunk of size 1826, which is longer than the specified 1000\n",
      "Created a chunk of size 1996, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 1884, which is longer than the specified 1000\n",
      "Created a chunk of size 1717, which is longer than the specified 1000\n",
      "Created a chunk of size 1215, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ Created 1250 chunks\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T10:27:53.339806Z",
     "start_time": "2025-09-23T17:22:34.296318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[4/4] Embedding and uploading to Pinecone...\")\n",
    "embs = embed_chunks([r[\"text\"] for r in records], model)\n",
    "save_to_pinecone(records, embs, pc, PINECONE_INDEX_NAME, namespace=NAMESPACE)\n",
    "print(f\"\\nâœ… Done! Uploaded {len(records)} chunks to Pinecone namespace '{NAMESPACE}'.\")"
   ],
   "id": "a55d9a50b91dcc13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/5] Embedding and uploading to Pinecone...\n",
      "ðŸ“Œ Saved 1250 vectors to Pinecone namespace 'ENG-spacy'.\n",
      "\n",
      "âœ… Done! Uploaded 1250 chunks to Pinecone namespace 'ENG-spacy'.\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
